# Voice Features Architecture & Flow

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Browser (Frontend)                       â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ User Interface                                           â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚ â”‚ Chat Input Area                                    â”‚  â”‚   â”‚
â”‚  â”‚ â”‚ [Text Input] [ğŸ¤] [Send]                          â”‚  â”‚   â”‚
â”‚  â”‚ â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚ â”‚ Chat History                                       â”‚  â”‚   â”‚
â”‚  â”‚ â”‚ - User: Hello!                                     â”‚  â”‚   â”‚
â”‚  â”‚ â”‚ - Bot: Hi there! [ğŸ”Š] [ğŸ‘] [ğŸ‘]                  â”‚  â”‚   â”‚
â”‚  â”‚ â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚ â”‚ Settings                                           â”‚  â”‚   â”‚
â”‚  â”‚ â”‚ â–¡ Auto-play voice replies                         â”‚  â”‚   â”‚
â”‚  â”‚ â”‚ Voice Speed: [====â—===] 1.0x                      â”‚  â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Web APIs                                                 â”‚   â”‚
â”‚  â”‚ - MediaRecorder (Audio Capture)                         â”‚   â”‚
â”‚  â”‚ - Web Speech API (Synthesis)                            â”‚   â”‚
â”‚  â”‚ - Fetch API (HTTP Requests)                             â”‚   â”‚
â”‚  â”‚ - localStorage (Settings)                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“â†‘
                    HTTP/HTTPS (Port 3000)
                              â†“â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Server (Backend)                            â”‚
â”‚                       Node.js/Express                            â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ API Endpoints                                            â”‚   â”‚
â”‚  â”‚ - POST /api/voice-to-text     (Speech Recognition)      â”‚   â”‚
â”‚  â”‚ - POST /api/text-to-speech    (TTS Ready)               â”‚   â”‚
â”‚  â”‚ - POST /api/chat              (Chat Messages)            â”‚   â”‚
â”‚  â”‚ - POST /api/analyze           (Sentiment Analysis)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ AI Models                                                â”‚   â”‚
â”‚  â”‚ - Whisper (Speech Recognition)                          â”‚   â”‚
â”‚  â”‚ - Llama 3.2 (Chat via Ollama)                           â”‚   â”‚
â”‚  â”‚ - BERT (Sentiment Analysis)                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Voice Input Flow Diagram

```
User â†’ ğŸ¤ Click â†’ MediaRecorder Start â†’ User Speaks â†’ ğŸ¤ Click to Stop
                                                              â†“
Audio Blob â†’ FormData â†’ POST /api/voice-to-text â†’ Whisper AI Processing
                                                              â†“
Recognized Text â† Response JSON â† Backend Processing
                â†“
Text Input Field â† Auto-populate
                â†“
Auto-Send to Chat â†’ POST /api/chat â†’ Display Response
```

### Detailed Voice Input Steps

```
1. User clicks ğŸ¤ button
   â†“
2. Browser requests microphone permission
   â†“
3. getUserMedia() called
   â†“
4. MediaRecorder initialized with audio stream
   â†“
5. state.isRecording = true
   â†“
6. UI updates: Button turns red, animation starts
   â†“
7. User speaks into microphone
   â†“
8. Audio data captured in chunks
   â†“
9. User clicks â¹ï¸ button
   â†“
10. mediaRecorder.stop() called
    â†“
11. Audio chunks assembled into Blob
    â†“
12. FormData created with audio file
    â†“
13. POST request to /api/voice-to-text
    â†“
14. Server processes with Whisper model
    â†“
15. Recognized text returned
    â†“
16. Text inserted into input field
    â†“
17. handleSendMessage() called automatically
    â†“
18. Chat flow continues normally
```

## Voice Output Flow Diagram

```
Bot Response Message â†’ displayMessage('assistant', text)
                â†“
Create ğŸ”Š button
                â†“
User clicks ğŸ”Š OR Auto-play enabled
                â†“
speakMessage(text) called
                â†“
SpeechSynthesisUtterance created
                â†“
Set rate = state.voiceSpeed
                â†“
window.speechSynthesis.speak()
                â†“
Browser synthesizes voice
                â†“
Audio plays through speakers/headphones
```

### Detailed Voice Output Steps

```
1. Bot sends response
   â†“
2. displayMessage('assistant', content) called
   â†“
3. Message displayed in chat
   â†“
4. ğŸ”Š button added to message
   â†“
5. If state.voiceEnabled = true:
   - Auto-play triggers after 500ms
   - speakMessage(content) called
   â†“
6. SpeechSynthesisUtterance created
   â†“
7. Set properties:
   - utterance.rate = state.voiceSpeed
   - utterance.pitch = 1
   - utterance.volume = 1
   â†“
8. window.speechSynthesis.speak(utterance)
   â†“
9. Browser's TTS engine processes text
   â†“
10. Audio synthesized and queued
    â†“
11. Audio plays through system audio output
    â†“
12. User hears voice response
    â†“
13. Can click ğŸ”Š again to replay
```

## Settings Persistence Flow

```
Page Load
    â†“
init() called
    â†“
Check localStorage:
â”œâ”€ 'voiceEnabled'
â””â”€ 'voiceSpeed'
    â†“
Found? â†’ Restore values to state and UI
    â†“
Update UI checkboxes/sliders
    â†“
User changes settings
    â†“
Event listeners trigger:
â”œâ”€ voiceToggle.change â†’ state.voiceEnabled = checked
â”‚                     â†’ localStorage.setItem()
â””â”€ voiceSpeedSlider.input â†’ state.voiceSpeed = value
                          â†’ localStorage.setItem()
    â†“
Settings saved (persists on refresh)
```

## Error Handling Flow

```
Voice Feature
    â†“
Try Block
    â”œâ”€ Success â†’ Normal Flow
    â””â”€ Error â†’ Catch Block
         â†“
    Error Type?
    â”œâ”€ Microphone Denied
    â”‚  â””â”€ showNotification('âŒ Microphone access denied')
    â”œâ”€ No Speech Recognized
    â”‚  â””â”€ showNotification('âŒ Could not recognize speech')
    â”œâ”€ Network Error
    â”‚  â””â”€ showNotification('âŒ Connection error')
    â””â”€ Unknown Error
       â””â”€ showNotification('âŒ ' + error.message)
         â†“
    Log error to console
         â†“
    User can retry
```

## State Management

```
state object
â”‚
â”œâ”€ Voice State
â”‚  â”œâ”€ isRecording (boolean)
â”‚  â”œâ”€ mediaRecorder (object)
â”‚  â”œâ”€ audioChunks (array)
â”‚  â”œâ”€ voiceEnabled (boolean) - localStorage
â”‚  â””â”€ voiceSpeed (number) - localStorage
â”‚
â”œâ”€ Chat State
â”‚  â”œâ”€ messages (array)
â”‚  â”œâ”€ conversationHistory (array)
â”‚  â”œâ”€ isLoading (boolean)
â”‚  â””â”€ temperature (number)
â”‚
â””â”€ Analytics State
   â”œâ”€ totalMessages (number)
   â”œâ”€ sentiments (object)
   â”œâ”€ feedback (object)
   â””â”€ conversationStart (date)
```

## API Call Sequence Diagram

```
Client                          Server                    AI Models
  â”‚                               â”‚                           â”‚
  â”œâ”€ POST /api/voice-to-text â”€â”€â†’ â”‚                           â”‚
  â”‚  (audio file)               â”‚  â”œâ”€ Parse FormData       â”‚
  â”‚                             â”‚  â”œâ”€ Load Whisper â”€â”€â”€â”€â†’ Whisper AI
  â”‚                             â”‚  â”‚                        â”‚
  â”‚                             â”‚  â† Process audio â†â”€â”€â”€â”€â”€â”€ â”‚
  â”‚                             â”‚  â”‚                        â”‚
  â”‚  â† Response JSON â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚                        â”‚
  â”‚  {text, confidence}         â”‚  â”‚                        â”‚
  â”‚                             â”‚  â”‚                        â”‚
  â”œâ”€ POST /api/chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚                           â”‚
  â”‚  (messages)                 â”‚  â”œâ”€ Call Ollama â”€â”€â”€â†’ Llama 3.2
  â”‚                             â”‚  â”‚                        â”‚
  â”‚                             â”‚  â† Get response â†â”€â”€â”€â”€â”€â”€ â”‚
  â”‚                             â”‚  â”‚                        â”‚
  â”‚  â† Response JSON â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚                        â”‚
  â”‚  {response}                 â”‚  â”‚                        â”‚
  â”‚                             â”‚  â”‚                        â”‚
  â”œâ”€ POST /api/analyze â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚                           â”‚
  â”‚  (text)                     â”‚  â”œâ”€ Call BERT â”€â”€â”€â”€â†’ BERT Model
  â”‚                             â”‚  â”‚                        â”‚
  â”‚                             â”‚  â† Analyze â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
  â”‚                             â”‚  â”‚                        â”‚
  â”‚  â† Response JSON â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚                        â”‚
  â”‚  {sentiment, intent}        â”‚  â”‚                        â”‚
```

## Local Storage Schema

```
localStorage
â”‚
â”œâ”€ 'voiceEnabled' (string: 'true' or 'false')
â”‚  Usage: Save whether auto-play is enabled
â”‚  
â”œâ”€ 'voiceSpeed' (string: number like '1.0')
â”‚  Usage: Save selected voice speed
â”‚  
â”œâ”€ 'chatbot_conversations' (JSON string)
â”‚  Usage: Save all conversations (existing)
â”‚  
â””â”€ Other settings (existing)
```

## Dependency Tree

```
server.js
â”œâ”€ express
â”œâ”€ multer (NEW)
â”œâ”€ axios
â”œâ”€ cors
â”œâ”€ dotenv
â””â”€ @xenova/transformers

public/app.js
â”œâ”€ window.navigator.mediaDevices (built-in)
â”œâ”€ window.MediaRecorder (built-in)
â”œâ”€ window.speechSynthesis (built-in)
â”œâ”€ localStorage (built-in)
â””â”€ fetch API (built-in)

public/index.html
â””â”€ styles.css

public/styles.css
â””â”€ CSS variables (custom properties)
```

## Feature Interaction Map

```
                    Chat System
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“          â†“    â†“    â†“          â†“
     Analytics  Settings Voice Chat  History
         â”‚          â”‚      â”‚     â”‚       â”‚
         â†“          â†“      â†“     â†“       â†“
    Sentiment   Speed   Input Output Records
    Feedback    Toggle  (STT) (TTS)
    Intent            Button Button
```

---

## Summary

The voice features integrate seamlessly with the existing chatbot:

1. **Input**: Captured via browser â†’ Sent to server â†’ Processed by AI â†’ Text returned â†’ Sent to chat
2. **Output**: Bot response â†’ Displayed â†’ Synthesized to speech â†’ Played through speakers
3. **Settings**: Saved locally â†’ Persisted across sessions â†’ Applied globally
4. **Error Handling**: Graceful fallbacks â†’ User notifications â†’ Console logging
5. **Performance**: Non-blocking â†’ Asynchronous â†’ Real-time feedback

All features work together without interfering with existing functionality.
